{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading files into mongodb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient # Install for using this lib.\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbname = 'test'\n",
    "collection_name1 = 'reviews'\n",
    "collection_name2 = 'business'\n",
    "collection_name3 = 'users'\n",
    "\n",
    "path = \"/Users/alvira/Desktop/distributedData/project/\"\n",
    "\n",
    "input_file_name1 = path+\"review.json\"\n",
    "input_file_name2 = path+'business.json'\n",
    "input_file_name3 = path+'user.json'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_query(dbname, collection_name, input_file_name):\n",
    "    mongoimport_query =  'mongoimport --db ' + dbname + ' --collection ' + collection_name + ' --file ' + input_file_name\n",
    "    #COMPLETE THIS.\n",
    "    return mongoimport_query\n",
    " \n",
    "#Create connection \n",
    "client = MongoClient() #default-localhost:27017\n",
    "#Connect to database\n",
    "db = client[dbname]\n",
    "\n",
    "#Drop table.\n",
    "db[collection_name1].drop()\n",
    "db[collection_name2].drop()\n",
    "db[collection_name3].drop()\n",
    "\n",
    "#Insert all data from the input_file_name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mongoimport_query = import_query(dbname, collection_name1, input_file_name1)\n",
    "subprocess.call(mongoimport_query,shell=True)\n",
    "\n",
    "mongoimport_query = import_query(dbname, collection_name2, input_file_name2)\n",
    "subprocess.call(mongoimport_query,shell=True)\n",
    "\n",
    "mongoimport_query = import_query(dbname, collection_name3, input_file_name3)\n",
    "subprocess.call(mongoimport_query,shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db.reviews.find()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep only restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants = db.business.find({ '$or' : [ { \"attributes.RestaurantsReservations\" : {'$exists' : 'true'} }, { \"attributes.RestaurantsDelivery\" : {'$exists':'true'}}, \n",
    "                            { \"attributes.RestaurantsAttire\" : {'$exists':'true'}}, { \"attributes.RestaurantsCounterService\" : {'$exists':'true'}}, \n",
    "                            { \"attributes.RestaurantsGoodForGroups\" : {'$exists':'true'}}, { \"attributes.RestaurantsPriceRange2\" : {'$exists':'true'}}, \n",
    "                            { \"attributes.RestaurantsTableService\" : {'$exists':'true'}}, { \"attributes.RestaurantsTakeOut\" : {'$exists':'true'}}, \n",
    "                            { \"attributes.GoodForMeal\" : {'$exists':'true'}}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(restaurants))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding restuarants having review counts greater than 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants = db.business.find({ '$or' : [ { \"attributes.RestaurantsReservations\" : {'$exists' : 'true'} }, { \"attributes.RestaurantsDelivery\" : {'$exists':'true'}}, \n",
    "                            { \"attributes.RestaurantsAttire\" : {'$exists':'true'}}, { \"attributes.RestaurantsCounterService\" : {'$exists':'true'}}, \n",
    "                            { \"attributes.RestaurantsGoodForGroups\" : {'$exists':'true'}}, { \"attributes.RestaurantsPriceRange2\" : {'$exists':'true'}}, \n",
    "                            { \"attributes.RestaurantsTableService\" : {'$exists':'true'}}, { \"attributes.RestaurantsTakeOut\" : {'$exists':'true'}}, \n",
    "                            { \"attributes.GoodForMeal\" : {'$exists':'true'}}], \n",
    "                    \"review_count\":{\"$gt\": 100}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest = list(restaurants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting business ID's\n",
    "business_ids = []\n",
    "for i in range(len(rest)):\n",
    "    business_ids.append(rest[i]['business_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8322"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(business_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(db.business.find({ '$or' : [ { \"attributes.RestaurantsReservations\" : {'$exists' : 'true'} }, { \"attributes.RestaurantsDelivery\" : {'$exists':'true'}}, \n",
    "#                             { \"attributes.RestaurantsAttire\" : {'$exists':'true'}}, { \"attributes.RestaurantsCounterService\" : {'$exists':'true'}}, \n",
    "#                             { \"attributes.RestaurantsGoodForGroups\" : {'$exists':'true'}}, { \"attributes.RestaurantsPriceRange2\" : {'$exists':'true'}}, \n",
    "#                             { \"attributes.RestaurantsTableService\" : {'$exists':'true'}}, { \"attributes.RestaurantsTakeOut\" : {'$exists':'true'}}, \n",
    "#                             { \"attributes.GoodForMeal\" : {'$exists':'true'}}]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Filtering users (having reviews count greater than 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_users = db.users.find({\"review_count\":{\"$gt\": 50}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = list(filtered_users )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = []\n",
    "for i in range(len(user)):\n",
    "    user_ids.append(user[i]['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112146"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Filtering reviews basis above user_id & business_id and stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(list(db.reviews.find()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_reviews = db.reviews.find({\"user_id\": {'$in':user_ids}, \"business_id\": {'$in':business_ids}, \n",
    "                                    \"stars\": {'$in':[1,2,3,4,5]}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review = list(filtered_reviews )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "883429"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saving filtered reviews as a table:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext.getOrCreate()\n",
    "sqlContext = SQLContext(sc)\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.filtered_reviews.drop()\n",
    "result = db.filtered_reviews.insert_many(filtered_reviews)\n",
    "# result.inserted_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load tables into pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = spark.read.format(\"com.mongodb.spark.sql.DefaultSource\").option(\"uri\",\"mongodb://127.0.0.1/test.filtered_reviews\").load()\n",
    "\n",
    "# business = spark.read.format(\"com.mongodb.spark.sql.DefaultSource\").option(\"uri\",\"mongodb://127.0.0.1/test.business\").load()\n",
    "\n",
    "# users = spark.read.format(\"com.mongodb.spark.sql.DefaultSource\").option(\"uri\",\"mongodb://127.0.0.1/test.users\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----+----------+-----+--------------------+-----+--------------------+------+--------------------+\n",
      "|                 _id|         business_id|cool|      date|funny|           review_id|stars|                text|useful|             user_id|\n",
      "+--------------------+--------------------+----+----------+-----+--------------------+-----+--------------------+------+--------------------+\n",
      "|[5a5bde777cb40ff2...|mr4FiPaXTWlJ3qGzp...|   0|2009-07-21|    0|Z5l99h18E3_g1GLcD...|    3|I left Table 17 f...|     3|djpMXOA1ic5wv3FPt...|\n",
      "+--------------------+--------------------+----+----------+-----+--------------------+-----+--------------------+------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "883429"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del filtered_reviews, filtered_users, restaurants, user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews.select(['business_id', 'user_id', 'text', 'stars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# business = business.select(['business_id', 'stars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# users = users.select(['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext.getOrCreate()\n",
    "sqlContext = SQLContext(sc)\n",
    "import pyspark.mllib.feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorize = udf(lambda (x) : int(x>3))\n",
    "reviews2 = reviews.withColumn('class',categorize('stars')).select(['text', 'class','stars','business_id', 'user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del business_ids, reviews, rest, user_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews2.repartition(1).write.json(path+\"reviews2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string\n",
    "regex = re.compile('[^a-zA-Z]')\n",
    "def words(text):\n",
    "    c = regex.sub(' ', text)\n",
    "    lis = re.sub(r'\\b\\w{1,2}\\b', '', c).split()\n",
    "    return set(map(lambda x: x.lower(), lis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize = udf(lambda (x) : words(x))\n",
    "# reviews2 = reviews2.withColumn(\"features\", tokenize(\"text\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews2 = reviews2.select([\"class\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|class| count|\n",
      "+-----+------+\n",
      "|    0|287851|\n",
      "|    1|595578|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews2.groupby(\"class\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+--------------------+--------------------+\n",
      "|                text|class|stars|         business_id|             user_id|\n",
      "+--------------------+-----+-----+--------------------+--------------------+\n",
      "|I left Table 17 f...|    0|    3|mr4FiPaXTWlJ3qGzp...|djpMXOA1ic5wv3FPt...|\n",
      "|Ok, full disclosu...|    1|    5|mr4FiPaXTWlJ3qGzp...|XCDxUzBSY8-JOvcp4...|\n",
      "|for the time bein...|    0|    3|mr4FiPaXTWlJ3qGzp...|-pXs08gJq9ExIk275...|\n",
      "|Found this place ...|    1|    4|mr4FiPaXTWlJ3qGzp...|Kf10dTiGlcnyhj8DB...|\n",
      "|Table 17 is a cla...|    0|    3|mr4FiPaXTWlJ3qGzp...|zZy5Jljx7rEvISiJ2...|\n",
      "|I wasn't super im...|    0|    3|mr4FiPaXTWlJ3qGzp...|Jyi0WJt0UfGdEg0gr...|\n",
      "|I'm going to igno...|    1|    4|mr4FiPaXTWlJ3qGzp...|JUT0U3HTSB3kz9Wh7...|\n",
      "|I love this place...|    1|    4|mr4FiPaXTWlJ3qGzp...|AhoxHm569hH_PRkoe...|\n",
      "|Booked through Op...|    1|    4|mr4FiPaXTWlJ3qGzp...|gXQfe8T1UvMpmR5rc...|\n",
      "|I came here for w...|    1|    4|mr4FiPaXTWlJ3qGzp...|alUuOskFSl1bODjnc...|\n",
      "|I came here with ...|    0|    3|mr4FiPaXTWlJ3qGzp...|qt1b6zXExL-uoJGRR...|\n",
      "|Literally my FAVO...|    1|    5|mr4FiPaXTWlJ3qGzp...|f-dzSIu2QURZ8Y_fx...|\n",
      "|Had a very lovely...|    1|    5|mr4FiPaXTWlJ3qGzp...|FYAkhIj29gyWD_Lte...|\n",
      "|Food: 9.5/10\n",
      "Atmo...|    1|    5|mr4FiPaXTWlJ3qGzp...|wu-ijx0ZiBThoc9tR...|\n",
      "|This hidden gem i...|    1|    5|mr4FiPaXTWlJ3qGzp...|a39kizwaoThU6uLIv...|\n",
      "|We were back here...|    1|    4|mr4FiPaXTWlJ3qGzp...|J3ucveGKKJDvtuCNn...|\n",
      "|I left Table 17 a...|    1|    5|mr4FiPaXTWlJ3qGzp...|LRKmxCcf6ZkxyujPd...|\n",
      "|I wish I could sh...|    0|    2|mr4FiPaXTWlJ3qGzp...|2VKVhy1SwaixHCeiW...|\n",
      "|Brunchy time and ...|    1|    4|mr4FiPaXTWlJ3qGzp...|Yl7OYdHuYmr7K-IW9...|\n",
      "|Is the food at Ta...|    1|    4|mr4FiPaXTWlJ3qGzp...|Oxe8DXjBOi6C-cR2w...|\n",
      "+--------------------+-----+-----+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer, StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = NaiveBayes.train(training, 1.0)\n",
    "# # Make prediction and test accuracy.\n",
    "# predictionAndLabel = test.map(lambda p: (model.predict(p.features), p.label))\n",
    "# accuracy = 1.0 * predictionAndLabel.filter(lambda pl: pl[0] == pl[1]).count() / test.count()\n",
    "# print('model accuracy {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, test = reviews2.select(['text', 'class','stars']).randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177207"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_stars = training.select([\"stars\"]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_stars = test.select([\"stars\"]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176962"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(test_stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training = training.select([\"text\",\"class\"])\n",
    "# test = test.select([\"text\",\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177252"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      " |-- class: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 metric = 0.813997\n"
     ]
    }
   ],
   "source": [
    "categoryIndexer = StringIndexer(inputCol=\"class\", outputCol=\"label\")\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"features\", numFeatures=20000)\n",
    "nb = NaiveBayes(smoothing=1.0)\n",
    "\n",
    "# categoryConverter = IndexToString(inputCol=\"label\", outputCol=\"predCategory\", labels=categoryIndexer.labels)\n",
    "pipeline = Pipeline(stages=[categoryIndexer, tokenizer, hashingTF, nb])\n",
    "\n",
    "model = pipeline.fit(training)\n",
    "pr = model.transform(test)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "metric = evaluator.evaluate(pr)\n",
    "\n",
    "print \"F1 metric = %g\" % metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "def prob2star(val): \n",
    "    if val < 0.2: return int(1)\n",
    "    elif val >= 0.2 and val < 0.4: return int(2)\n",
    "    elif val >= 0.4 and val < 0.6: return int(3)\n",
    "    elif val >= 0.6 and val < 0.8: return int(4)\n",
    "    else: return int(5)\n",
    "#     return val\n",
    "get_star = udf(lambda (x) : prob2star(x[1]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr2 = pr.withColumn(\"pred_stars\", get_star('probability'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(stars=4, pred_stars=u'1', probability=DenseVector([0.9991, 0.0009]), label=0.0, prediction=0.0),\n",
       " Row(stars=4, pred_stars=u'1', probability=DenseVector([0.9709, 0.0291]), label=0.0, prediction=0.0),\n",
       " Row(stars=5, pred_stars=u'1', probability=DenseVector([0.995, 0.005]), label=0.0, prediction=0.0),\n",
       " Row(stars=2, pred_stars=u'3', probability=DenseVector([0.4497, 0.5503]), label=1.0, prediction=1.0),\n",
       " Row(stars=3, pred_stars=u'1', probability=DenseVector([0.8682, 0.1318]), label=1.0, prediction=0.0),\n",
       " Row(stars=5, pred_stars=u'1', probability=DenseVector([0.9949, 0.0051]), label=0.0, prediction=0.0),\n",
       " Row(stars=2, pred_stars=u'5', probability=DenseVector([0.0004, 0.9996]), label=1.0, prediction=1.0),\n",
       " Row(stars=3, pred_stars=u'1', probability=DenseVector([0.9937, 0.0063]), label=1.0, prediction=0.0),\n",
       " Row(stars=4, pred_stars=u'1', probability=DenseVector([0.9104, 0.0896]), label=0.0, prediction=0.0),\n",
       " Row(stars=2, pred_stars=u'5', probability=DenseVector([0.1782, 0.8218]), label=1.0, prediction=1.0)]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr2.select([\"stars\",\"pred_stars\",\"probability\",\"label\", \"prediction\"]).take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "toIntfunc = udf(lambda x: x,IntegerType())\n",
    "pr2 = pr2.withColumn(\"pred_stars\",toIntfunc(\"pred_stars\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      " |-- class: string (nullable = true)\n",
      " |-- stars: integer (nullable = true)\n",
      " |-- label: double (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = true)\n",
      " |-- pred_stars: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pr2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "def rmse(x,y):\n",
    "    return math.sqrt(np.mean((np.array(x)-np.array(y))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "u'requirement failed: Column pred_stars must be of type DoubleType but was actually IntegerType.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-148-083600d0b99f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mevaluator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMulticlassClassificationEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabelCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"stars\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictionCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pred_stars\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetricName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpr2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.2.0/libexec/python/pyspark/ml/evaluation.pyc\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Params must be a param map but got %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.2.0/libexec/python/pyspark/ml/evaluation.pyc\u001b[0m in \u001b[0;36m_evaluate\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \"\"\"\n\u001b[1;32m     98\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0misLargerBetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.2.0/libexec/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.2.0/libexec/python/pyspark/sql/utils.pyc\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mQueryExecutionException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'java.lang.IllegalArgumentException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mIllegalArgumentException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m: u'requirement failed: Column pred_stars must be of type DoubleType but was actually IntegerType.'"
     ]
    }
   ],
   "source": [
    "#Can soemone help in resolving this error\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"stars\", predictionCol=\"pred_stars\", metricName=\"accuracy\")\n",
    "metric = evaluator.evaluate(pr2)\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr2 = pr2.withColumn(\"square\", (pr2[\"stars\"]-pr2[\"pred_stars\"])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = pr2.select(mean(\"square\")).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.98544816538\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "rmse = math.sqrt(mean[0][0])\n",
    "print rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|square|count|\n",
      "+------+-----+\n",
      "|   0.0| 8310|\n",
      "|   1.0|19756|\n",
      "|   4.0|32826|\n",
      "|   9.0|61481|\n",
      "|  16.0|54197|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pr2.select(\"square\").groupby(\"square\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
